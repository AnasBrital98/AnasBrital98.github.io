<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Anas Brital


  | Xception Architecture Explained .

</title>
<meta name="description" content="This is my personal blog where I share my thoughts and what I've learned until now .
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üë®‚Äçüéì</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/blog/2021/Xception-CNN-Architecture-Explained/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       Anas Brital
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Xception Architecture Explained .</h1>
    <p class="post-meta">September 9, 2021</p>   
  </header>

  <article class="post-content">
    <p><strong>Paper :</strong> <a href="https://arxiv.org/pdf/1610.02357.pdf">Xception: Deep Learning with Depthwise Separable Convolutions</a>.</p>

<p><strong>Authors :</strong> Fran√ßois Chollet. Google.</p>

<p><strong>Published in :</strong> 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</p>

<p><strong>Model Architecture :</strong></p>

<div align="center">
<img src="/assets/img/9/XceptionModel.svg" width="600px" height="300px" />
</div>

<p><b>Conv-A Block : </b></p>
<div align="center">
<img src="/assets/img/9/ConvA.svg" width="600px" height="300px" />
</div>

<p><b>Conv-B Block : </b></p>
<div align="center">
<img src="/assets/img/9/ConvB.svg" width="600px" height="300px" />
</div>

<p><b>Conv-C Block : </b></p>
<div align="center">
<img src="/assets/img/9/ConvC.svg" width="600px" height="300px" />
</div>

<p><strong>keras :</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
</pre></td><td class="code"><pre><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers.merge</span> <span class="kn">import</span> <span class="n">concatenate</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span> <span class="p">,</span> <span class="n">MaxPool2D</span> <span class="p">,</span> <span class="n">SeparableConv2D</span> <span class="p">,</span> <span class="n">Input</span> <span class="p">,</span> <span class="n">GlobalAveragePooling2D</span> <span class="p">,</span> <span class="n">Dense</span> <span class="p">,</span> <span class="n">Dropout</span> <span class="p">,</span><span class="n">Activation</span> <span class="p">,</span> <span class="n">BatchNormalization</span>

<span class="k">def</span> <span class="nf">conv_2d</span><span class="p">(</span><span class="n">prev_layer</span><span class="p">,</span><span class="n">nbr_filters</span> <span class="p">,</span> <span class="n">filter_size</span> <span class="p">,</span> <span class="n">strides</span> <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">False</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="n">nbr_filters</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">filter_size</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span> <span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">prev_layer</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">activation</span> <span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">)</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>    

<span class="k">def</span> <span class="nf">sep_conv_2d</span><span class="p">(</span><span class="n">prev_layer</span><span class="p">,</span><span class="n">nbr_filters</span> <span class="p">,</span> <span class="n">filter_size</span> <span class="p">,</span> <span class="n">strides</span> <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">False</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">SeparableConv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="n">nbr_filters</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">filter_size</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="n">strides</span> <span class="p">,</span><span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">prev_layer</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">activation</span> <span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">)</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">ConvBlockA</span><span class="p">(</span><span class="n">prev_layer</span> <span class="p">,</span> <span class="n">nbr_filters</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)):</span>
    
    <span class="n">branch1</span> <span class="o">=</span> <span class="n">conv_2d</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">prev_layer</span><span class="p">,</span><span class="n">nbr_filters</span> <span class="o">=</span> <span class="n">nbr_filters</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    
    <span class="n">branch2</span> <span class="o">=</span> <span class="n">sep_conv_2d</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">prev_layer</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="n">nbr_filters</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="n">filter_size</span><span class="p">,</span> <span class="n">strides</span> <span class="o">=</span> <span class="n">strides</span> <span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">branch2</span> <span class="o">=</span> <span class="n">sep_conv_2d</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">branch2</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="n">nbr_filters</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="n">filter_size</span><span class="p">,</span> <span class="n">strides</span> <span class="o">=</span> <span class="n">strides</span> <span class="p">)</span>
    <span class="n">branch2</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)</span> <span class="p">(</span><span class="n">branch2</span><span class="p">)</span>
    
    <span class="n">output</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">([</span><span class="n">branch1</span> <span class="p">,</span> <span class="n">branch2</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">output</span>

<span class="k">def</span> <span class="nf">ConvBlockB</span><span class="p">(</span><span class="n">prev_layer</span> <span class="p">):</span>
    <span class="n">branch1</span> <span class="o">=</span> <span class="n">prev_layer</span>
    
    <span class="n">branch2</span> <span class="o">=</span> <span class="n">sep_conv_2d</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">prev_layer</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">728</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">branch2</span> <span class="o">=</span> <span class="n">sep_conv_2d</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">branch2</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">728</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">branch2</span> <span class="o">=</span> <span class="n">sep_conv_2d</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">branch2</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">728</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="n">output</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">([</span><span class="n">branch1</span> <span class="p">,</span> <span class="n">branch2</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">output</span>

<span class="k">def</span> <span class="nf">ConvBlockC</span><span class="p">(</span><span class="n">prev_layer</span> <span class="p">):</span>
    <span class="n">branch1</span> <span class="o">=</span> <span class="n">conv_2d</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">prev_layer</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    
    <span class="n">branch2</span> <span class="o">=</span> <span class="n">sep_conv_2d</span><span class="p">(</span><span class="n">prev_layer</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">728</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">)</span>    
    <span class="n">branch2</span> <span class="o">=</span> <span class="n">sep_conv_2d</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">branch2</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">branch2</span> <span class="o">=</span> <span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">)(</span><span class="n">branch2</span><span class="p">)</span>
    
    <span class="n">output</span> <span class="o">=</span> <span class="n">concatenate</span><span class="p">([</span><span class="n">branch1</span> <span class="p">,</span> <span class="n">branch2</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">sep_conv_2d</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">output</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">1536</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">sep_conv_2d</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">output</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>

<span class="k">def</span> <span class="nf">Xception</span><span class="p">():</span>
    
    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">299</span> <span class="p">,</span> <span class="mi">299</span> <span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">conv_2d</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">conv_2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">filter_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockA</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">128</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockA</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">256</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockA</span><span class="p">(</span><span class="n">prev_layer</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">nbr_filters</span> <span class="o">=</span> <span class="mi">728</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockB</span><span class="p">(</span><span class="n">prev_layer</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockB</span><span class="p">(</span><span class="n">prev_layer</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockB</span><span class="p">(</span><span class="n">prev_layer</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockB</span><span class="p">(</span><span class="n">prev_layer</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockB</span><span class="p">(</span><span class="n">prev_layer</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockB</span><span class="p">(</span><span class="n">prev_layer</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockB</span><span class="p">(</span><span class="n">prev_layer</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockB</span><span class="p">(</span><span class="n">prev_layer</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlockC</span><span class="p">(</span><span class="n">prev_layer</span><span class="o">=</span><span class="n">x</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">2048</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">input_layer</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">x</span> <span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s">'Xception'</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p><strong>pyTorch :</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torchsummary</span> <span class="kn">import</span> <span class="n">summary</span>

<span class="k">class</span> <span class="nc">separableConv2D</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span> <span class="p">,</span> <span class="n">in_channels</span> <span class="p">,</span> <span class="n">out_channels</span> <span class="p">,</span> <span class="n">kernel_Size</span> <span class="p">,</span> <span class="n">activation</span> <span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">separableConv2D</span> <span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    
    <span class="bp">self</span><span class="p">.</span><span class="n">depthwise</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span> <span class="n">in_channels</span> <span class="p">,</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="n">in_channels</span> <span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_Size</span> <span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">in_channels</span> <span class="p">,</span><span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span> <span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">pointwise</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span> <span class="n">in_channels</span> <span class="p">,</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span> <span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">)</span>
    
    <span class="bp">self</span><span class="p">.</span><span class="n">batchNormalization</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_features</span> <span class="o">=</span> <span class="n">out_channels</span><span class="p">)</span>
    
    <span class="bp">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">activation</span>
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">depthwise</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pointwise</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">batchNormalization</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">act</span> <span class="p">:</span>
      <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">Conv_Block_A</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span> <span class="p">,</span> <span class="n">in_channels</span> <span class="p">,</span><span class="n">nbr_kernels</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv_Block_A</span> <span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">branch1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span> <span class="n">in_channels</span> <span class="p">,</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="n">nbr_kernels</span> <span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="bp">self</span><span class="p">.</span><span class="n">branch2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">separableConv2D</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span> <span class="p">,</span><span class="n">out_channels</span> <span class="o">=</span>  <span class="n">nbr_kernels</span> <span class="p">,</span> <span class="n">kernel_Size</span> <span class="o">=</span> <span class="mi">3</span>  <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="p">,</span> 
        <span class="n">separableConv2D</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">nbr_kernels</span> <span class="p">,</span><span class="n">out_channels</span> <span class="o">=</span>  <span class="n">nbr_kernels</span> <span class="p">,</span> <span class="n">kernel_Size</span> <span class="o">=</span> <span class="mi">3</span>  <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">False</span><span class="p">),</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span> <span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span> <span class="p">,</span> <span class="n">x</span><span class="p">):</span>

    <span class="n">branch1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">branch1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
   
    <span class="n">branch2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">branch2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">branch2</span><span class="p">(</span><span class="n">branch2</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">branch1</span> <span class="p">,</span> <span class="n">branch2</span> <span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">Conv_Block_B</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">in_channels</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv_Block_B</span> <span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">branch1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">separableConv2D</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span> <span class="p">,</span><span class="n">out_channels</span> <span class="o">=</span>  <span class="mi">728</span> <span class="p">,</span> <span class="n">kernel_Size</span> <span class="o">=</span> <span class="mi">3</span>  <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="p">,</span>
        <span class="n">separableConv2D</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">728</span> <span class="p">,</span><span class="n">out_channels</span> <span class="o">=</span>  <span class="mi">728</span> <span class="p">,</span> <span class="n">kernel_Size</span> <span class="o">=</span> <span class="mi">3</span>  <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">True</span><span class="p">),</span>
        <span class="n">separableConv2D</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">728</span> <span class="p">,</span><span class="n">out_channels</span> <span class="o">=</span>  <span class="mi">728</span> <span class="p">,</span> <span class="n">kernel_Size</span> <span class="o">=</span> <span class="mi">3</span>  <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span> 
    <span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span> <span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">branch1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">branch1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">branch1</span><span class="p">(</span><span class="n">branch1</span><span class="p">)</span>

    <span class="n">branch2</span> <span class="o">=</span> <span class="n">x</span> 

    <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">branch1</span> <span class="p">,</span> <span class="n">branch2</span><span class="p">]</span> <span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">Conv_Block_C</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">in_channels</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Conv_Block_C</span> <span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">branch1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">separableConv2D</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span> <span class="p">,</span><span class="n">out_channels</span> <span class="o">=</span>  <span class="mi">728</span> <span class="p">,</span> <span class="n">kernel_Size</span> <span class="o">=</span> <span class="mi">3</span>  <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="p">,</span>
        <span class="n">separableConv2D</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">728</span> <span class="p">,</span><span class="n">out_channels</span> <span class="o">=</span>  <span class="mi">1024</span> <span class="p">,</span> <span class="n">kernel_Size</span> <span class="o">=</span> <span class="mi">3</span>  <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span> <span class="p">,</span>
        <span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span> <span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">branch2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span> <span class="p">,</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="mi">1024</span> <span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">)</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">sepconv1</span> <span class="o">=</span> <span class="n">separableConv2D</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">2048</span> <span class="p">,</span><span class="n">out_channels</span> <span class="o">=</span>  <span class="mi">1536</span> <span class="p">,</span> <span class="n">kernel_Size</span> <span class="o">=</span> <span class="mi">3</span>  <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">sepconv1</span> <span class="o">=</span> <span class="n">separableConv2D</span><span class="p">(</span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">1536</span> <span class="p">,</span><span class="n">out_channels</span> <span class="o">=</span>  <span class="mi">2048</span> <span class="p">,</span> <span class="n">kernel_Size</span> <span class="o">=</span> <span class="mi">3</span>  <span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
 
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span> <span class="p">,</span> <span class="n">x</span><span class="p">):</span>
   <span class="n">branch1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
   <span class="n">branch1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">branch1</span><span class="p">(</span><span class="n">branch1</span><span class="p">)</span>

   <span class="n">branch2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">branch2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

   <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">branch1</span> <span class="p">,</span> <span class="n">branch2</span><span class="p">]</span> <span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

   <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sepconv1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
   <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">sepconv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

   <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">Xception</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Xception</span> <span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span> <span class="mi">3</span> <span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span> <span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span> <span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span> <span class="mi">32</span> <span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span> <span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_A_1</span> <span class="o">=</span> <span class="n">Conv_Block_A</span><span class="p">(</span><span class="mi">32</span> <span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_A_2</span> <span class="o">=</span> <span class="n">Conv_Block_A</span><span class="p">(</span><span class="mi">128</span> <span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_A_3</span> <span class="o">=</span> <span class="n">Conv_Block_A</span><span class="p">(</span><span class="mi">256</span> <span class="p">,</span> <span class="mi">728</span><span class="p">)</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_B_1</span>   <span class="o">=</span> <span class="n">Conv_Block_B</span><span class="p">(</span><span class="mi">728</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_B_2</span>   <span class="o">=</span> <span class="n">Conv_Block_B</span><span class="p">(</span><span class="mi">1536</span><span class="p">)</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_C</span>   <span class="o">=</span> <span class="n">Conv_Block_B</span><span class="p">(</span><span class="mi">1536</span><span class="p">)</span>

    <span class="bp">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2048</span> <span class="p">,</span> <span class="n">out_features</span><span class="o">=</span> <span class="mi">2048</span> <span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">2048</span> <span class="p">,</span> <span class="n">out_features</span><span class="o">=</span> <span class="mi">1000</span> <span class="p">)</span>
  
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span> <span class="p">,</span> <span class="n">x</span><span class="p">):</span>

    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'After Conv1 : '</span> <span class="p">,</span> <span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'After Conv2 : '</span> <span class="p">,</span> <span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_A_1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'After Block A_1 : '</span><span class="p">,</span><span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_A_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'After Block A_2 : '</span><span class="p">,</span><span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_A_3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'After Block A_3 : '</span><span class="p">,</span><span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_B_1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_B_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_B_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_B_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_B_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_B_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_B_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_B_2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'After Block B : '</span><span class="p">,</span><span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">convBlock_C</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'After Block C : '</span><span class="p">,</span><span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()(</span><span class="n">out</span><span class="p">)</span>

    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Softmax</span><span class="p">()(</span><span class="n">out</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">out</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Xception</span><span class="p">()</span>

<span class="n">summary</span><span class="p">(</span><span class="n">model</span> <span class="p">,</span> <span class="p">(</span><span class="mi">3</span> <span class="p">,</span> <span class="mi">299</span> <span class="p">,</span> <span class="mi">299</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></figure>

  </article>

</div>

    </div>
  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
