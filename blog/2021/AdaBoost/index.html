<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Anas Brital


  | AdaBoost Algorithm Explained .

</title>
<meta name="description" content="This is my personal blog where I share my thoughts and what I've learned until now .
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üë®‚Äçüéì</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/blog/2021/AdaBoost/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       Anas Brital
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">AdaBoost Algorithm Explained .</h1>
    <p class="post-meta">September 21, 2021</p>   
  </header>

  <article class="post-content">
    <p><strong>Paper :</strong> <a href="https://www.sciencedirect.com/science/article/pii/S002200009791504X">A Decision-Theoretic Generalization of On-Line Learning
and an Application to Boosting</a> .</p>

<p><strong>Authors :</strong> Yoav Freund and Robert E. Schapire .</p>

<p><strong>Published in:</strong> AT6T Labs 1996 .</p>

<hr />

<p>Before talking about AdaBoost we need to explain what is Boosting ?</p>

<p>Boosting is an ensemble meta-algorithm in supervised learning, and a family of machine learning algorithms that convert <strong>weak learners</strong> to strong ones. Boosting is based on the question posed by <strong>Kearns</strong> and <strong>Valiant</strong>  <a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning)">[1]</a> .</p>

<center>
**"Can a set of weak learners create a single strong learner?"**
</center>

<p>The Boosting technique is described as follows :</p>
<div align="center">
<img src="/assets/img/21/boosting.PNG" width="300" height="100" />
</div>

<p>Where f_t is a weak classifier that takes a sample x as input and return the class of it , and T is the number of weak learners .</p>

<p><strong>as you can see in the formula above , the Weak classifiers contribute to the final result with the same amount , this is exacly the difference between a simple Boosting algorithm and AdaBosst , in AdaBoost the weak learners contribute with a value conrespending to their performance .</strong></p>

<p>The PseudoCode of AdaBoost is defined as following :</p>

<p>The Boosting technique is described as follows :</p>
<div align="center">
<img src="/assets/img/21/AdaBoostPseudoCode.PNG" width="500" height="300" />
</div>

<p>The Formula used to predict a certain sample is defined in the following :</p>

<div align="center">
<img src="/assets/img/21/AdaBoostPredict.png" width="300" height="100" />
</div>

<blockquote>
  <p><strong>As you can see in the formula above every Weak classifier contribute to the result with a value corresponding to his performance , This is The difference between a simple Boosting algorithm and AdaBoost.</strong></p>
</blockquote>

<h4 id="implementation-">Implementation :</h4>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">class</span> <span class="nc">DecisionStump</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">classLabel</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feature</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span> <span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">Feature</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="bp">self</span><span class="p">.</span><span class="n">feature</span><span class="p">]</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">Feature</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span> <span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">classLabel</span> <span class="p">,</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">classLabel</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">predictions</span>

<span class="k">class</span> <span class="nc">AdaBoost</span><span class="p">:</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span> <span class="p">,</span> <span class="n">nbr_classifiers</span> <span class="o">=</span> <span class="mi">10</span> <span class="p">,</span> <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-10</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">nbr_classifiers</span> <span class="o">=</span> <span class="n">nbr_classifiers</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">classifiers</span> <span class="o">=</span> <span class="p">[]</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span> <span class="p">,</span> <span class="n">x</span> <span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span>
        <span class="c1">#Initialize The weights for all the samples with 1 / nbr_samples
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">full</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span> <span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">nbr_classifiers</span><span class="p">):</span>
            <span class="n">Weak_Classifier_i</span> <span class="o">=</span> <span class="n">DecisionStump</span><span class="p">()</span>
            <span class="n">minimum_Error</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">"inf"</span><span class="p">)</span>
            
            <span class="c1">#Iterate Over all the features to find the perfect one that will split our data
</span>            <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">current_Feature</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">x_train</span><span class="p">[:,</span><span class="n">feature</span><span class="p">]</span>
                <span class="c1">#find thresholds Values which is the unique values of the feature that we're working with
</span>                <span class="n">thresholds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">current_Feature</span><span class="p">)</span>
                <span class="c1">#iterate over all the thresholds to find the perfect one that will split the current feature
</span>                <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">:</span>
                    <span class="s">"""
                    we don't know what the class of samples where feature &lt; threshold , this is way we will test with class 1 ,
                    if the error more than 0.5 which is mean the majority of the samples that we calssified as 1 are -1 , so what we will do in this case ?
                    we will flip the error and assign -1 to our class label .
                    
                    if error (label used is 1) = 0.8 
                    then error(label is -1) = 0.2 .
                    
                    """</span>
                    <span class="n">class_Label</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">current_Feature</span> <span class="o">&lt;</span> <span class="n">threshold</span> <span class="p">,</span> <span class="n">class_Label</span> <span class="p">,</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">class_Label</span><span class="p">)</span>
                    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">weights</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">y_train</span> <span class="o">!=</span> <span class="n">predictions</span><span class="p">])</span>
                    <span class="c1">#flip The Error and The classLabel
</span>                    <span class="k">if</span> <span class="n">error</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="p">:</span>
                        <span class="n">error</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">error</span>
                        <span class="n">class_Label</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
                    <span class="c1">#if we find a better error less than the previous (we initialize The Error with float("if") which is a very small number)     
</span>                    <span class="k">if</span> <span class="n">error</span> <span class="o">&lt;</span> <span class="n">minimum_Error</span><span class="p">:</span>
                        <span class="n">Weak_Classifier_i</span><span class="p">.</span><span class="n">classLabel</span> <span class="o">=</span> <span class="n">class_Label</span>
                        <span class="n">Weak_Classifier_i</span><span class="p">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
                        <span class="n">Weak_Classifier_i</span><span class="p">.</span><span class="n">feature</span> <span class="o">=</span> <span class="n">feature</span>
                        <span class="n">minimum_Error</span> <span class="o">=</span> <span class="n">error</span>                    
            <span class="c1">#Calculate The Performance of the Current Weak Classifier            
</span>            <span class="n">Weak_Classifier_i</span><span class="p">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">minimum_Error</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">epsilon</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">minimum_Error</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">epsilon</span><span class="p">))</span>        
            
            <span class="c1">#Update The Weights
</span>            <span class="n">predictions</span> <span class="o">=</span> <span class="n">Weak_Classifier_i</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">x_train</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">weights</span> <span class="o">*=</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span> <span class="o">-</span> <span class="n">Weak_Classifier_i</span><span class="p">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">predictions</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">y_train</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">weights</span><span class="p">))</span>
            <span class="c1">#save our Weak Classifier
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">classifiers</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">Weak_Classifier_i</span><span class="p">)</span>
            
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span> <span class="p">,</span> <span class="n">x</span><span class="p">):</span>
         <span class="n">classifiers_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">classifier</span><span class="p">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">classifier</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">classifiers</span><span class="p">]</span>
         <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">classifiers_predictions</span> <span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
         <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">sign</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
     
    <span class="k">def</span> <span class="nf">plotTheModel</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">fig</span> <span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
        <span class="n">Weak_Classifiers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">Errors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">nbr_classifiers</span><span class="p">):</span>
            <span class="n">Weak_Classifiers</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">"c"</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
            <span class="n">Errors</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">classifiers</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">Weak_Classifiers</span> <span class="p">,</span> <span class="n">Errors</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Error"</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"classifiers"</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Error of classifiers"</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">#Test AdaBoost 
</span><span class="sb">``</span><span class="err">`</span>

<span class="c1">#### Testing The Model :
</span>
<span class="sb">``</span><span class="err">`</span><span class="n">python</span>
<span class="k">def</span> <span class="nf">Accuracy</span><span class="p">(</span><span class="n">y</span> <span class="p">,</span> <span class="n">y_hat</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">!=</span> <span class="n">y_hat</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>


<span class="n">x</span> <span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span> <span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">10</span> <span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">2</span> <span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x_train</span> <span class="p">,</span> <span class="n">x_test</span> <span class="p">,</span> <span class="n">y_train</span> <span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span> <span class="p">,</span> <span class="n">y</span> <span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

<span class="n">adaBoost</span>  <span class="o">=</span> <span class="n">AdaBoost</span><span class="p">()</span>
<span class="n">adaBoost</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">adaBoost</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">adaBoost</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"AdaBoost Accuracy : "</span><span class="p">,</span><span class="n">Accuracy</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">))</span>
<span class="n">adaBoost</span><span class="p">.</span><span class="n">plotTheModel</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></figure>

<h4 id="the-performance-of-each-weak-classifier-that-we-get-is-">The Performance of each Weak Classifier that we get is :</h4>

<div align="center">
<img src="/assets/img/21/AdaBoostResult.png" width="400" height="200" />
</div>

  </article>

</div>

    </div>
  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
